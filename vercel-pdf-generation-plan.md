# Supabase âœ Vercel PDF Generation â€“ **Stepâ€‘byâ€‘Step Guide**

> **Date:** 22â€¯Mayâ€¯2025  ãƒ»  **Author:** (your name)

---

## ğŸ§  Why are we doing this?

1. **Symptom** â€“â€¯When users request printâ€‘quality PDFs (>â€¯4â€¯MB) the Supabase Edge Function sometimes crashes or silently drops the connection; no file is delivered.
2. **Root causes**

   * 256â€¯MB memory cap and â‰ˆâ€¯2â€¯CPUâ€‘seconds quota per Edge Function invocation.
   * Cloudflareâ€‘style limits: max 4â€¯MB inbound body, â‰ˆâ€¯32â€¯MB outbound body.
   * User JWT can already be expired when the function call starts (secondary issue, to be fixed later).
3. **Solution in one sentence** â€“â€¯Render the PDF inside a **Vercel Serverless Function** (Node runtime, up to 3â€¯GB RAM / 5â€¯min) and immediately upload the finished file back into the existing **`documents`** bucket in Supabase Storage; return a signed URL to the client so the file is served via Supabaseâ€™s CDN, not through Vercel.

---

## ğŸ“‹  Prerequisites

* A **Vercel Pro** project (needed to set `memory=3009`â€¯MB and `maxDuration=300`â€¯s).
* Your existing **Supabase project** with the `documents` Storage bucket.
* **Nodeâ€¯18+** and npm/pnpm for local dev.
* The Supabase **serviceâ€‘role key** available as an envÂ var.

Add these environment variables in Vercel â†’ *Project â†’ Settings â†’ Environment Variables*:

```bash
SUPABASE_URL=https://<project-id>.supabase.co
SUPABASE_SERVICE_ROLE_KEY=<service-role>
```

---

## ğŸ› ï¸  StepÂ 1 â€“ Scaffold the API route on Vercel

```bash
mkdir -p app/api/generate-pdf
code       app/api/generate-pdf/route.ts
```

Paste the boilerâ€‘plate below (adjust bucket/region as needed):

```ts
// /api/generate-pdf   (Next.jsÂ 14 route)
export const runtime     = 'nodejs';  // full Node env
export const memory      = 3009;      // MB â€“ Pro max
export const maxDuration = 300;       // seconds

import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

export async function POST(req: Request) {
  /* 1ï¸âƒ£  Parse payload; fetch DB rows & images here */

  // 2ï¸âƒ£  Generate the PDF (Buffer or stream)
  const pdf = await buildPdf(/* data, images */);

  /* 3ï¸âƒ£  Upload to Supabase Storage */
  const path = `pdfs/${crypto.randomUUID()}.pdf`;
  const { error } = await supabase
    .storage.from('documents')
    .upload(path, pdf, {
      contentType: 'application/pdf',
      upsert: false,
    });
  if (error) return new Response(JSON.stringify({ error }), { status: 500 });

  /* 4ï¸âƒ£  Return a 15â€‘min signed URL */
  const { data } = await supabase
    .storage.from('documents')
    .createSignedUrl(path, 900);

  return Response.json({ url: data?.signedUrl });
}
```

> **TipÂ â€¢** Libraries like `pdfkit`, `pdf-lib`, or `@react-pdf/renderer` can stream output so you never hold the whole PDF in RAM.

---

## ğŸ“¦  StepÂ 2 â€“ Implement `buildPdf()` with **pdfme**

The existing EdgeÂ Function already uses **pdfme** (`@pdfme/generator`) plus custom plugins. Weâ€™ll keep that exact stackâ€”just move it to Node land.

### 2â€‘AÂ Â Add the dependency (npm)

```bash
npm install @pdfme/generator @pdfme/common @pdfme/schemas pdf-lib
```

*(If you use pnpm or Yarn, swap in `pnpm add â€¦` or `yarn add â€¦` respectively.)*

### 2â€‘BÂ Â Port your helper codeÂ Â Port your helper code

Create `lib/pdf/buildPdf.ts` with:

```ts
import { promises as fs } from 'node:fs';
import path from 'node:path';
import { generate } from '@pdfme/generator';
import { text, image, line, table, rectangle } from '@pdfme/schemas';
import type { Template, Font } from '@pdfme/common';

// ğŸ–¼ï¸  bring over your hexâ†’rgb, mmâ†’pt, iconTextList plugin exactly as in the Deno file
import { hexToRgb, mm2pt, iconTextList } from './helpers';

export async function buildPdf(input: {
  productId: string;
  /* any other fields you pass from the route */
}) {
  // 1. Load template JSON and fonts from the filesystem (relative to project root)
  const templatePath = path.resolve(process.cwd(), 'pdf/template/datasheet-template.json');
  const fontDir      = path.resolve(process.cwd(), 'pdf/fonts');

  const template: Template = JSON.parse(await fs.readFile(templatePath, 'utf8'));
  const fonts: Font = {
    'Poppins-Bold':   { data: await fs.readFile(path.join(fontDir, 'Poppins-Bold.ttf')),   subset: true },
    'Inter-Regular':  { data: await fs.readFile(path.join(fontDir, 'Inter-Regular.ttf')),  subset: true, fallback: true },
    'Inter-Bold':     { data: await fs.readFile(path.join(fontDir, 'Inter-Bold.ttf')),     subset: true },
  };

  // 2. Fetch DB row + images exactly like the old admin client did (inside the route)
  //    â†’ pass them in via the function args so buildPdf stays pure

  const inputs = [/* build the same pdfInputs array as before */];

  // 3. Generate the PDF â€“ identical call signature
  const pdfBytes = await generate({
    template,
    inputs,
    options: { font: fonts },
    plugins: { text, image, line, Table: table, rectangle, iconTextList },
  });

  return Buffer.from(pdfBytes); // Vercel upload expects Buffer | Uint8Array
}
```

*Everything inside the plugin remains untouchedâ€”pdfme works the same under Node.*

### 2â€‘CÂ Â Keep memory usage low

* Stream any **5â€¯MB** product image through `sharp` or `@pdfme/image-utils` to downâ€‘scale if necessary.
* Do **not** keep multiple PDFs in memory; generate, upload, discard.

Now `buildPdf()` returns a Node `Buffer`, which the route uploads to Supabase Storage.

---

## ğŸ”‘  StepÂ 3 â€“ Swap the client call

Below is the **oneâ€‘liner** you already use inside `DatasheetGeneratorForm.tsx` (Edge Function version) and the **new** call youâ€™ll use after the migration.

```ts
// OLD â€” calls Supabase Edge Function (Deno runtime)
const { data: generateData, error: generateError } =
  await supabase.functions.invoke("generate-datasheet", {
    body: { productId: savedProductId, userId: user.id },
  });
```

```ts
// NEW â€” calls the Vercel route you just created
const res = await fetch("/api/generate-pdf", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ productId: savedProductId }),
});
const { url, error } = await res.json();
if (error) throw new Error(error);
window.open(url, "_blank");
```

**Key points**

1. **Same payload** â€“ the Vercel route accepts the same `{ productId }` (and whatever else you need).
2. **No `supabase.functions.invoke`** â€“ the PDF job now lives in your Next.js API layer, so a regular `fetch` (or `axios`) call is enough.
3. **Signed URL returned** â€“ the handler already returns `{ url }`; you no longer need to call `storage.createSignedUrl()` on the client.

Replace the old block in `generateAndOpenPdf()` with the new one, delete the extra signedâ€‘URL step, and the rest of the toast logic can stay the same.

---

## ğŸ§ª  StepÂ 4 â€“ Test locally

1. `vercel dev`
2. POST sample payload to [http://localhost:3000/api/generate-pdf](http://localhost:3000/api/generate-pdf)
3. Verify:

   * HTTPÂ 200 with `{ url }` JSON.
   * PDF appears in **documents** bucket.
   * Download succeeds and file size is >â€¯4.5â€¯MB (proves we bypass Vercel limit).

---

## â˜ï¸  StepÂ 5 â€“ Deploy to Vercel Pro

```bash
vercel --prod
```

Ensure the project is on **Pro** before relying on >â€¯1024â€¯MB memory.

---

## ğŸ“ˆ  StepÂ 6 â€“ Monitor and optimise

* Check *Vercel â†’ Functions â†’ Logs* for memory/duration graphs.
* Wrap `buildPdf()` with `console.time()` to spot regressions.
* Alert when â‰¥â€¯5â€¯% of `/api/generate-pdf` requests return 5XX.

---

## ğŸ·ï¸  StepÂ 7 â€“ Decommission the old Edge Function

1. Remove any client code calling the Supabase Edge Function.
2. Delete the function from Supabase Dashboard.
3. Reclaim duplicate Storage assets created during migration tests.

---

## ğŸ’°  Cost & Quotas Cheatâ€‘Sheet (summary)

* **Vercel Pro** â€“ 1â€¯M invocations & 1â€¯000â€¯GBâ€‘hours compute per month included.
* **Supabase Storage egress** â€“ first 250â€¯GB/month free; at 20â€¯MB per PDF thatâ€™s \~12â€¯000 downloads.
* **Supabase object size** â€“ 5â€¯GB per simple upload, 50â€¯GB via resumable endpoint.

---

## ğŸ§°  Troubleshooting Quickâ€‘Hits

* **Outâ€‘ofâ€‘memory crash in Vercel** â†’ raise `export const memory` or stream images/PDF data.
* **413Â â€œEntity Too Largeâ€** â†’ you accidentally returned the PDF in the HTTP response; make sure you upload to Storage instead.
* **400Â `invalid_jwt` before PDF starts** â†’ the client sent an expired token; refresh session *before* calling the endpoint.

---

ğŸ **Done!** Your PDF generation now enjoys GBâ€‘level RAM, 5â€‘minute ceilings, and the same Storage bucketâ€”without ever hitting Vercelâ€™s 4.5â€¯MB response limit.
